{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a DC GAN (with an architecture of your choice) on the given data\n",
    "with the usual GAN loss. Plot the loss curves for the Generator and\n",
    "Discriminator losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Animals_data\"  \n",
    "\n",
    "ngpu = 1 #number of gpu available\n",
    "img_size = 128\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "z=100 #latent space size\n",
    "\n",
    "workers = 4 #number of workers for dataloader\n",
    "\n",
    "gf = 64 #generator filter size\n",
    "df = 64 #discriminator filter size\n",
    "\n",
    "lr = 0.0002 #learning rate\n",
    "beta1 = 0.5 #beta1 for adam\n",
    "epochs = 5 #number of epochs to train for\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset  =  datasets.ImageFolder(root=data_dir, transform=transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]))\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights Initialization (According to DCGAN paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights initialization for the generator and discriminator\n",
    "# In DC-GAN, the authors specify that all model weights shall be randomly initialized from a Normal distribution with mean=0, stdev=0.02. Using the same \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(Generator, self).__init__()  \n",
    "        self.gen = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=z, out_channels=gf*16, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(gf*16),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=gf*16, out_channels=gf*8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(gf*8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=gf*8, out_channels=gf*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(gf*4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=gf*4, out_channels=gf*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(gf*2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=gf*2, out_channels=gf, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(gf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=gf, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()\n",
    "            \n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.gen(input)\n",
    "    \n",
    "print(Generator())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gen_model = Generator().to(device)\n",
    "\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    Gen_model = nn.DataParallel(Gen_model, device_ids=[0, 1])\n",
    "    \n",
    "Gen_model.apply(weights_init) # apply the weights_init function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=df, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=df, out_channels=df*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(df*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=df*2, out_channels=df*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(df*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=df*4, out_channels=df*8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(df*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=df*8, out_channels=df*16, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(df*16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=df*16, out_channels=1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "            \n",
    "        )\n",
    "    def forward(self, input, noise_variance):\n",
    "        \n",
    "        input = input + noise_variance*torch.randn_like(input)\n",
    "        return self.disc(input)\n",
    "    \n",
    "print(Discriminator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disc_model = Discriminator().to(device)\n",
    "\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    Disc_model = nn.DataParallel(Disc_model, device_ids=[0, 1])\n",
    "    \n",
    "Disc_model.apply(weights_init) # apply the weights_init function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(64, z, 1, 1, device=device)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "disc_lr = 0.00005\n",
    "gen_lr = 0.0002\n",
    "\n",
    "optimizerD = optim.Adam(Disc_model.parameters(), lr=disc_lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(Gen_model.parameters(), lr=gen_lr, betas=(beta1, 0.999))\n",
    "\n",
    "# optimizerD = optim.Adam(Disc_model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "# optimizerG = optim.Adam(Gen_model.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "gen_losses = [] \n",
    "disc_losses = []\n",
    "label_smoothing = False\n",
    "noise_variance = 0.2\n",
    "gen_updates = 3\n",
    "disc_updates = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 0\n",
    "num_epochs = 1000\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i,data in enumerate(dataloader, 0):\n",
    "       \n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        \n",
    "        \n",
    "       \n",
    "            \n",
    "        # update Disc model : maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        Disc_model.zero_grad()\n",
    "        label = torch.full((b_size,), real_label, device=device, dtype=torch.float)\n",
    "        output = Disc_model(real_cpu, noise_variance).view(-1)\n",
    "        \n",
    "        \n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "        \n",
    "        noise = torch.randn(b_size, z, 1, 1, device=device)\n",
    "        fake = Gen_model(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = Disc_model(fake.detach(), noise_variance).view(-1)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "    \n",
    "        disc_losses.append(errD.item())\n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "            \n",
    "        # update Gen model : maximize log(D(G(z)))\n",
    "        Gen_model.zero_grad()\n",
    "        label = torch.full((b_size,), real_label, device=device, dtype=torch.float)\n",
    "        # noise = torch.randn(b_size, z, 1, 1, device=device)\n",
    "        # fake = Gen_model(noise)\n",
    "        output = Disc_model(fake, noise_variance).view(-1)\n",
    "        \n",
    "  \n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        gen_losses.append(errG.item())\n",
    "            \n",
    "    \n",
    "        if i % 10 == 0:\n",
    "            \n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                    % (epoch, num_epochs, i, len(dataloader),\n",
    "                        errD.item() ,\n",
    "                        errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "            \n",
    "        if (iters)%500 == 0 or (i == len(dataloader)-1) or (epoch == num_epochs-1):\n",
    "            with torch.no_grad():\n",
    "                fake = Gen_model(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "            plt.imsave(f\"new_images_unbalanced/{epoch}_{iters}.png\", img_list[-1].numpy().transpose((1,2,0)))\n",
    "            \n",
    "        iters += 1\n",
    "        \n",
    "    if epoch%10 == 0:\n",
    "        torch.save(Gen_model.state_dict(), \"models/Gen_model.pth\")\n",
    "        torch.save(Disc_model.state_dict(), \"models/Disc_model.pth\")\n",
    "        \n",
    "       \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(gen_losses,label=\"G\")\n",
    "plt.plot(disc_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
